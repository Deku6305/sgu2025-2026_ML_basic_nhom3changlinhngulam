{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f070b0c7",
   "metadata": {},
   "source": [
    "# Mục tiêu là sử dụng mô hình seq2seq để classification tất cả các nghệ sĩ đã biết (đã label) \n",
    "+ sau khi train xong thì loại bỏ FC cuối để lấy đc embedding vector của các tác giả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471fdca",
   "metadata": {},
   "source": [
    "## Import thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16b3a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itables import show  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0eaa7",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcfd46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(\"../exps/Preproccessed/exp2_vocab.csv\")  # columns: word,id\n",
    "vocab = dict(zip(vocab_df[\"Artist Name\"], vocab_df['Class']))\n",
    "vocab_size = len(vocab) + 1  # +1 for unknown token\n",
    "train_df = pd.read_csv(\"../exps/Preproccessed/exp2_NamesLabeling_Train.csv\")  # columns: text,label\n",
    "test_df  = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57106f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, loss=304.7251\n",
      "Epoch 2/10, loss=174.2586\n",
      "Epoch 3/10, loss=133.8014\n",
      "Epoch 4/10, loss=123.7112\n",
      "Epoch 5/10, loss=120.0811\n",
      "Epoch 6/10, loss=114.7362\n",
      "Epoch 7/10, loss=114.5876\n",
      "Epoch 8/10, loss=113.3978\n",
      "Epoch 9/10, loss=112.3976\n",
      "Epoch 10/10, loss=112.2584\n",
      "Test Accuracy: 0.8231292517006803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1. Load vocab\n",
    "# -----------------------------\n",
    "vocab_df = pd.read_csv(\"../exps/Preproccessed/exp2_vocab.csv\")  # columns: word,id\n",
    "vocab = dict(zip(vocab_df[\"Artist Name\"], vocab_df['Class']))\n",
    "vocab_size = len(vocab) + 1  # +1 for unknown token\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load train/test\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"../exps/Preproccessed/exp2_NamesLabeling_Train.csv\")  # columns: text,label\n",
    "test_df  = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Tokenizer for comma-separated text\n",
    "# -----------------------------\n",
    "def text_to_ids(text, vocab):\n",
    "    # Split by comma, strip spaces, lowercase if needed\n",
    "    tokens = [tok.strip() for tok in re.split(r',\\s*', text)]\n",
    "    ids = [vocab.get(tok, 0) for tok in tokens]  # unknown token -> 0\n",
    "    return ids\n",
    "\n",
    "train_df['seq'] = train_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "test_df['seq']  = test_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Encode labels to integers\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "train_df['Class'] = le.fit_transform(train_df['Class'])\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Prepare sequences and Class\n",
    "# -----------------------------\n",
    "train_sequences = train_df['seq'].tolist()\n",
    "train_Class    = train_df['Class'].tolist()\n",
    "\n",
    "test_sequences = test_df['seq'].tolist()\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_sequences, train_Class, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. PyTorch Dataset\n",
    "# -----------------------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded = nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return padded, torch.tensor(labels)\n",
    "\n",
    "train_dataset = TextDataset(train_sequences, train_Class)\n",
    "val_dataset   = TextDataset(X_val, y_val)\n",
    "# test_dataset  = TextDataset(test_sequences, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "# test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Define LSTM model\n",
    "# -----------------------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=1, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        x = self.embedding(x)\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        last_hidden = h[-1]  # shape: (batch, hidden_dim)\n",
    "        if return_embedding:\n",
    "            return last_hidden  # return vector instead of logits\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Training setup\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=16,\n",
    "    num_classes=11,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Training loop\n",
    "# -----------------------------\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, loss={total_loss:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Evaluation\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        logits = model(X_batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += len(y_batch)\n",
    "\n",
    "print(\"Test Accuracy:\", correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf20c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_ordered(sequences, model, device, batch_size=64):\n",
    "    # Tạo Dataset tạm thời\n",
    "    # Lưu ý: Labels để None vì ta chỉ cần X để lấy vector, không cần tính loss\n",
    "    dataset = TextDataset(sequences, [0]*len(sequences)) \n",
    "    \n",
    "    # QUAN TRỌNG NHẤT: shuffle=False để giữ đúng thứ tự index\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            # return_embedding=True để lấy vector\n",
    "            batch_emb = model(X_batch, return_embedding=True) \n",
    "            embeddings.append(batch_emb.cpu())\n",
    "            \n",
    "    # Nối các batch lại thành 1 tensor lớn\n",
    "    return torch.cat(embeddings, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f02f4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng file gốc cần ghép: Train=14396, Test=3600\n",
      "Đang trích xuất Train Embeddings...\n",
      "Đang trích xuất Test Embeddings...\n",
      "✅ Check OK: Số lượng dòng khớp nhau tuyệt đối.\n",
      "Đã lưu file thành công tại ../exps/Preproccessed/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!--| quarto-html-table-processing: none -->\n",
       "<table id=\"itables_cd638bea_1f9f_4277_a897_763c3b629485\"><tbody><tr>\n",
       "    <td style=\"vertical-align:middle; text-align:left\">\n",
       "    <a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "    Loading ITables v2.5.2 from the internet...\n",
       "    (need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "    </tr></tbody></table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.4.0/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import { ITable, jQuery as $ } from 'https://www.unpkg.com/dt_for_itables@2.4.0/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_cd638bea_1f9f_4277_a897_763c3b629485:not(.dataTable)\").forEach(table => {\n",
       "        if (!(table instanceof HTMLTableElement))\n",
       "            return;\n",
       "\n",
       "        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"style\": {\"table-layout\": \"auto\", \"width\": \"auto\", \"margin\": \"auto\", \"caption-side\": \"bottom\"}, \"order\": [], \"text_in_header_can_be_selected\": true, \"classes\": [\"display\", \"nowrap\"], \"table_html\": \"<table><thead>\\n    <tr style=\\\"text-align: right;\\\">\\n      \\n      <th>Id</th>\\n      <th>Artist Name</th>\\n      <th>Track Name</th>\\n      <th>Popularity</th>\\n      <th>danceability</th>\\n      <th>energy</th>\\n      <th>key</th>\\n      <th>loudness</th>\\n      <th>mode</th>\\n      <th>speechiness</th>\\n      <th>acousticness</th>\\n      <th>instrumentalness</th>\\n      <th>liveness</th>\\n      <th>valence</th>\\n      <th>tempo</th>\\n      <th>duration_in min/ms</th>\\n      <th>time_signature</th>\\n      <th>Class</th>\\n      <th>seq</th>\\n      <th>artist_emb_0</th>\\n      <th>artist_emb_1</th>\\n      <th>artist_emb_2</th>\\n      <th>artist_emb_3</th>\\n      <th>artist_emb_4</th>\\n      <th>artist_emb_5</th>\\n      <th>artist_emb_6</th>\\n      <th>artist_emb_7</th>\\n      <th>artist_emb_8</th>\\n      <th>artist_emb_9</th>\\n      <th>artist_emb_10</th>\\n      <th>artist_emb_11</th>\\n      <th>artist_emb_12</th>\\n      <th>artist_emb_13</th>\\n      <th>artist_emb_14</th>\\n      <th>artist_emb_15</th>\\n    </tr>\\n  </thead></table>\", \"data_json\": \"[[1, \\\"Marina Maximilian\\\", \\\"Not Afraid\\\", 37.0, 0.334, 0.536, 9.0, -6.649, 0, 0.0381, 0.378, \\\"___NaN___\\\", 0.106, 0.235, 152.429, 204947.0, 4, 9, \\\"[9]\\\", -0.952094, -0.965292, -0.964242, -0.590555, -0.96394, -0.917043, 0.899132, 0.960029, 0.319159, -0.97418, 0.941397, -0.941672, -0.982508, 0.057994, 0.972473, 0.017882], [2, \\\"The Black Keys\\\", \\\"Howlin' for You\\\", 67.0, 0.725, 0.747, 11.0, -5.545, 1, 0.0876, 0.0272, 0.0468, 0.104, 0.38, 132.921, 191956.0, 4, 6, \\\"[1]\\\", -0.961246, 0.9505, 0.985835, -0.944468, -0.972231, -0.978501, 0.96978, -0.454249, 0.309693, -0.9787, 0.731192, -0.989244, -0.970193, 0.084333, -0.929134, -0.591285], [3, \\\"Royal &amp; the Serpent\\\", \\\"phuck u\\\", \\\"___NaN___\\\", 0.584, 0.804, 7.0, -6.094, 1, 0.0619, 0.000968, 0.635, 0.284, 0.635, 159.953, 161037.0, 4, 10, \\\"[9]\\\", -0.952094, -0.965292, -0.964242, -0.590555, -0.96394, -0.917043, 0.899132, 0.960029, 0.319159, -0.97418, 0.941397, -0.941672, -0.982508, 0.057994, 0.972473, 0.017882], [4, \\\"Detroit Blues Band\\\", \\\"Missing You\\\", 12.0, 0.515, 0.308, \\\"___NaN___\\\", -14.711, 1, 0.0312, 0.907, 0.0213, 0.3, 0.501, 172.472, 298093.0, 3, 2, \\\"[2]\\\", -0.979598, 0.96473, 0.960556, -0.978103, 0.070854, 0.981339, -0.97936, -0.851089, 0.977742, 0.801031, 0.761772, 0.263656, 0.922071, -0.984323, -0.863202, -0.947057], [5, \\\"Coast Contra\\\", \\\"My Lady\\\", 48.0, 0.565, 0.777, 6.0, -5.096, 0, 0.249, 0.183, \\\"___NaN___\\\", 0.211, 0.619, 88.311, 254145.0, 4, 5, \\\"[5]\\\", 0.973528, 0.062881, -0.94313, 0.789975, 0.022602, -0.904145, -0.231495, -0.249917, -0.028067, 0.075399, -0.02012, 0.493624, -0.976917, 0.977271, 0.663085, -0.941997]]\"};\n",
       "        new ITable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Load lại File Gốc (Target Files)\n",
    "# Chúng ta cần trích xuất đặc trưng cho file gốc mà bạn muốn ghép cột vào\n",
    "# (Dù train trên file clean, nhưng predict phải chạy trên file gốc)\n",
    "full_train_target = pd.read_csv(\"../data/train.csv\")\n",
    "full_test_target  = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(f\"Số dòng file gốc cần ghép: Train={len(full_train_target)}, Test={len(full_test_target)}\")\n",
    "\n",
    "# 3. Chuẩn bị Sequence cho file gốc\n",
    "# Dùng vocab đã có để chuyển tên thành số\n",
    "full_train_target['seq'] = full_train_target['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "full_test_target['seq']  = full_test_target['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "\n",
    "# 4. Chạy trích xuất\n",
    "print(\"Đang trích xuất Train Embeddings...\")\n",
    "train_emb_data = get_embeddings_ordered(full_train_target['seq'].tolist(), model, device)\n",
    "\n",
    "print(\"Đang trích xuất Test Embeddings...\")\n",
    "test_emb_data  = get_embeddings_ordered(full_test_target['seq'].tolist(), model, device)\n",
    "\n",
    "# 5. Lưu kết quả\n",
    "# Tạo tên cột động: emb_0, emb_1...\n",
    "emb_dim = train_emb_data.shape[1]\n",
    "col_names = [f\"artist_emb_{i}\" for i in range(emb_dim)]\n",
    "\n",
    "df_train_emb = pd.DataFrame(train_emb_data, columns=col_names)\n",
    "df_test_emb  = pd.DataFrame(test_emb_data, columns=col_names)\n",
    "\n",
    "# Kiểm tra lần cuối\n",
    "if len(df_train_emb) == len(full_train_target):\n",
    "    print(\"✅ Check OK: Số lượng dòng khớp nhau tuyệt đối.\")\n",
    "    \n",
    "    # Lưu file\n",
    "    df_train_emb.to_csv(\"../exps/Preproccessed/train_embeddings_lstm.csv\", index=False)\n",
    "    df_test_emb.to_csv(\"../exps/Preproccessed/test_embeddings_lstm.csv\", index=False)\n",
    "    print(\"Đã lưu file thành công tại ../exps/Preproccessed/\")\n",
    "else:\n",
    "    print(f\"Lệch dòng! Gốc: {len(full_train_target)}, Emb: {len(df_train_emb)}\")\n",
    "\n",
    "# 6. (Tùy chọn) Ghép thử luôn để xem\n",
    "train_final = pd.concat([full_train_target, df_train_emb], axis=1)\n",
    "show(train_final.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

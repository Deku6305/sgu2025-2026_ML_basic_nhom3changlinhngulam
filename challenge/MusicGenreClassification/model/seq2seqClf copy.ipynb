{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f070b0c7",
   "metadata": {},
   "source": [
    "# Mục tiêu là sử dụng mô hình seq2seq để classification tất cả các nghệ sĩ đã biết (đã label) \n",
    "+ sau khi train xong thì loại bỏ FC cuối để lấy đc embedding vector của các tác giả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471fdca",
   "metadata": {},
   "source": [
    "## Import thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "16b3a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itables import show  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0eaa7",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fcfd46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(\"../exps/Preproccessed/exp2_vocab.csv\")  # columns: word,id\n",
    "train_df = pd.read_csv(\"../exps/Preproccessed/exp2_NamesLabeling_Train.csv\")  # columns: text,label\n",
    "test_df  = pd.read_csv(\"../data/test.csv\")\n",
    "# Lấy danh sách tất cả nghệ sĩ duy nhất từ vocab_df\n",
    "unique_artists = vocab_df['Artist Name'].unique()\n",
    "vocab = {name: idx + 1 for idx, name in enumerate(unique_artists)}\n",
    "vocab_size = len(vocab) + 2  # +1 for unknown token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d8831",
   "metadata": {},
   "source": [
    "# Chuyển text sang Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f5618ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(text, vocab):\n",
    "    # Split by comma, strip spaces, lowercase if needed\n",
    "    tokens = [tok.strip() for tok in re.split(r',\\s*', text)]\n",
    "    ids = [vocab.get(tok, 0) for tok in tokens]  # unknown token -> 0\n",
    "    return ids\n",
    "\n",
    "train_df['seq'] = train_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "test_df['seq']  = test_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "002cff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['Class'] = le.fit_transform(train_df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808284e",
   "metadata": {},
   "source": [
    "# Dataset và Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "abe3fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels=None):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.sequences[idx], dtype=torch.long)\n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return seq, label\n",
    "        return seq, torch.tensor(0) # Dummy label cho test\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    # Padding sequences để cùng độ dài\n",
    "    padded = nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return padded, torch.tensor(labels)\n",
    "\n",
    "# Split Train/Val (Giữ index để sau ghép lại đúng dòng)\n",
    "X_train_seq, X_val_seq, y_train, y_val = train_test_split(\n",
    "    train_df['seq'].tolist(), train_df['Class'].tolist(), \n",
    "    test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = TextDataset(train_df['seq'].tolist(), train_df['Class'])\n",
    "test_dataset  = TextDataset(test_df['seq'].tolist())\n",
    "# val_dataset   = TextDataset(X_val_seq, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "# Loader dùng để extract feature (không shuffle để giữ đúng thứ tự index)\n",
    "train_extract_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_extract_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfacb9e",
   "metadata": {},
   "source": [
    "# Mô hình LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "decd2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        x = self.embedding(x)\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        # Lấy hidden state cuối cùng làm vector đặc trưng\n",
    "        last_hidden = h[-1] \n",
    "        \n",
    "        if return_embedding:\n",
    "            return last_hidden # Trả về vector\n",
    "            \n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3430abff",
   "metadata": {},
   "source": [
    "# Khởi tạo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5f07a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=16,\n",
    "    num_classes=11,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0f0ce",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d9d6624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 184.6598 | Acc: 0.6042\n",
      "Epoch 2/10 | Loss: 169.6119 | Acc: 0.6413\n",
      "Epoch 3/10 | Loss: 159.1688 | Acc: 0.6708\n",
      "Epoch 4/10 | Loss: 147.7585 | Acc: 0.6887\n",
      "Epoch 5/10 | Loss: 140.8295 | Acc: 0.7062\n",
      "Epoch 6/10 | Loss: 134.9460 | Acc: 0.7203\n",
      "Epoch 7/10 | Loss: 128.4078 | Acc: 0.7314\n",
      "Epoch 8/10 | Loss: 120.4802 | Acc: 0.7453\n",
      "Epoch 9/10 | Loss: 117.2098 | Acc: 0.7499\n",
      "Epoch 10/10 | Loss: 111.6798 | Acc: 0.7576\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch) # Mặc định return_embedding=False\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += len(y_batch)\n",
    "        \n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f} | Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5405e",
   "metadata": {},
   "source": [
    "# Áp dụng model lên toàn bộ dữ liệu gốc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b8411b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng file gốc: Train=14396, Test=3600\n"
     ]
    }
   ],
   "source": [
    "full_train_df = pd.read_csv(\"../data/train.csv\") \n",
    "full_test_df  = pd.read_csv(\"../data/test.csv\")\n",
    "print(f\"Số dòng file gốc: Train={len(full_train_df)}, Test={len(full_test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "29a9a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df['seq'] = full_train_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))\n",
    "full_test_df['seq']  = full_test_df['Artist Name'].apply(lambda x: text_to_ids(x, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "04649c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = TextDataset(full_train_df['seq'].tolist(), labels=None) # Không cần label\n",
    "full_test_dataset  = TextDataset(full_test_df['seq'].tolist(), labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a2794d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_loader = DataLoader(full_train_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "full_test_loader  = DataLoader(full_test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eadb50f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang trích xuất Embedding cho toàn bộ 14k dòng...\n"
     ]
    }
   ],
   "source": [
    "def extract_embeddings_final(dataloader, model, device):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            # return_embedding=True để lấy vector thay vì kết quả phân loại\n",
    "            batch_emb = model(X_batch, return_embedding=True) \n",
    "            all_embeddings.append(batch_emb.cpu())\n",
    "            \n",
    "    return torch.cat(all_embeddings, dim=0).numpy()\n",
    "\n",
    "print(\"Đang trích xuất Embedding cho toàn bộ 14k dòng...\")\n",
    "\n",
    "# Chạy trích xuất\n",
    "final_train_emb = extract_embeddings_final(full_train_loader, model, device)\n",
    "final_test_emb  = extract_embeddings_final(full_test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3749aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Lưu kết quả\n",
    "# Tạo tên cột: artist_emb_0, artist_emb_1, ...\n",
    "emb_cols = [f\"artist_emb_{i}\" for i in range(final_train_emb.shape[1])]\n",
    "\n",
    "train_emb_df = pd.DataFrame(final_train_emb, columns=emb_cols)\n",
    "test_emb_df  = pd.DataFrame(final_test_emb, columns=emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e51d623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Đã xong!\n",
      "Shape gốc train: 14396 dòng\n",
      "Shape embedding mới: (14396, 16) (Phải khớp số dòng trên)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_emb_df.to_csv(\"../exps/Preproccessed/full_train_lstm_embeddings.csv\", index=False)\n",
    "test_emb_df.to_csv(\"../exps/Preproccessed/full_test_lstm_embeddings.csv\", index=False)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Đã xong!\")\n",
    "print(f\"Shape gốc train: {len(full_train_df)} dòng\")\n",
    "print(f\"Shape embedding mới: {train_emb_df.shape} (Phải khớp số dòng trên)\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1213a98",
   "metadata": {},
   "source": [
    "# import thư viện cần thiết\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebed6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a681e6",
   "metadata": {},
   "source": [
    "# Tạo dữ liệu giả định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cdafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1) \n",
    "m = len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c1c9c",
   "metadata": {},
   "source": [
    "# Khởi tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(1, 1)\n",
    "b = np.random.randn(1, 1) \n",
    "lr = 0.1 \n",
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc76733",
   "metadata": {},
   "source": [
    "# Tính toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6277be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (Batch Gradient Descent):\n",
      "Iteration 0: Loss=16.0693 | w=0.6131, b=1.9890\n",
      "Iteration 1: Loss=10.2689 | w=1.0888, b=2.4144\n",
      "Iteration 2: Loss=6.6167 | w=1.4657, b=2.7526\n",
      "Iteration 3: Loss=4.3171 | w=1.7643, b=3.0215\n",
      "Iteration 4: Loss=2.8691 | w=2.0007, b=3.2354\n",
      "Iteration 5: Loss=1.9574 | w=2.1879, b=3.4058\n",
      "Iteration 6: Loss=1.3833 | w=2.3359, b=3.5414\n",
      "Iteration 7: Loss=1.0217 | w=2.4528, b=3.6496\n",
      "Iteration 8: Loss=0.7940 | w=2.5452, b=3.7360\n",
      "Iteration 9: Loss=0.6506 | w=2.6180, b=3.8051\n",
      "Iteration 10: Loss=0.5603 | w=2.6753, b=3.8604\n",
      "Iteration 11: Loss=0.5034 | w=2.7204, b=3.9048\n",
      "Iteration 12: Loss=0.4675 | w=2.7557, b=3.9405\n",
      "Iteration 13: Loss=0.4448 | w=2.7833, b=3.9693\n",
      "Iteration 14: Loss=0.4306 | w=2.8048, b=3.9926\n",
      "Iteration 15: Loss=0.4215 | w=2.8214, b=4.0116\n",
      "Iteration 16: Loss=0.4158 | w=2.8342, b=4.0271\n",
      "Iteration 17: Loss=0.4122 | w=2.8440, b=4.0399\n",
      "Iteration 18: Loss=0.4098 | w=2.8513, b=4.0505\n",
      "Iteration 19: Loss=0.4083 | w=2.8568, b=4.0593\n",
      "\n",
      "Optimal parameters after 20 iterations: w=2.8568, b=4.0593\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression (Batch Gradient Descent):\")\n",
    "for i in range(n_iterations):\n",
    "    # Dự đoán\n",
    "    y_pred = X.dot(w) + b\n",
    "    \n",
    "    # Tính toán sai số\n",
    "    error = y_pred - y\n",
    "    \n",
    "    # Tính Loss (MSE - Mean Squared Error)\n",
    "    loss = np.sum(error**2) / (2 * m)\n",
    "    \n",
    "    # Tính Gradient\n",
    "    grad_w = X.T.dot(error) / m\n",
    "    grad_b = np.sum(error) / m\n",
    "    \n",
    "    # Cập nhật tham số\n",
    "    w = w - lr * grad_w\n",
    "    b = b - lr * grad_b\n",
    "    \n",
    "    print(f\"Iteration {i}: Loss={loss:.4f} | w={w[0][0]:.4f}, b={b[0][0]:.4f}\")\n",
    "\n",
    "print(f\"\\nOptimal parameters after 20 iterations: w={w[0][0]:.4f}, b={b[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
